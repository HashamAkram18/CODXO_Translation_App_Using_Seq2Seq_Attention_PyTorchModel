{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-kVVrZAx94h",
        "outputId": "b7647f69-cbdd-451b-d427-4365570b675c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kkRxTuOUPObc"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install indic-nlp-library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReCcLjI0Obpc",
        "outputId": "a932a448-4f3a-46b3-fbea-ea676d45893f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==2.3.0+cu121\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.3.0%2Bcu121-cp310-cp310-linux_x86_64.whl (781.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.0/781.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtext==0.18.0+cpu\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torchtext-0.18.0%2Bcpu-cp310-cp310-linux_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu121) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu121) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu121) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu121) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu121) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0+cu121) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0+cu121)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0+cu121)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0+cu121)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0+cu121)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0+cu121)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0+cu121)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0+cu121)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0+cu121)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0+cu121)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0+cu121)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0+cu121)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.3.0 (from torch==2.3.0+cu121)\n",
            "  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0+cpu) (4.66.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0+cpu) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0+cpu) (1.26.4)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0+cu121)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0+cu121) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0+cpu) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0+cpu) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0+cpu) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0+cpu) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0+cu121) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchtext\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.1\n",
            "    Uninstalling triton-2.3.1:\n",
            "      Successfully uninstalled triton-2.3.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.1+cu121\n",
            "    Uninstalling torch-2.3.1+cu121:\n",
            "      Successfully uninstalled torch-2.3.1+cu121\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.18.0\n",
            "    Uninstalling torchtext-0.18.0:\n",
            "      Successfully uninstalled torchtext-0.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.1+cu121 requires torch==2.3.1, but you have torch 2.3.0+cu121 which is incompatible.\n",
            "torchvision 0.18.1+cu121 requires torch==2.3.1, but you have torch 2.3.0+cu121 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 torch-2.3.0+cu121 torchtext-0.18.0+cpu triton-2.3.0\n"
          ]
        }
      ],
      "source": [
        "%pip install torch==2.3.0+cu121 torchtext==0.18.0+cpu -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OK!\n"
          ]
        }
      ],
      "source": [
        "print(\"OK!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JRt9DgoIzVC",
        "outputId": "875a950d-f263-46ab-a63c-0020cf633a00"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Home\\anaconda3\\envs\\E_to_U\\lib\\site-packages\\torchtext\\data\\__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "c:\\Users\\Home\\anaconda3\\envs\\E_to_U\\lib\\site-packages\\torchtext\\vocab\\__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "c:\\Users\\Home\\anaconda3\\envs\\E_to_U\\lib\\site-packages\\torchtext\\utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchtext\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "from torch.nn.functional import one_hot\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "import unicodedata\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from indicnlp.tokenize.sentence_tokenize import sentence_split\n",
        "from indicnlp.tokenize.indic_tokenize import trivial_tokenize_urdu\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5c4LyPbN1A3",
        "outputId": "1a2690e5-337f-4402-b690-2b1e74da8775"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torchtext version: 0.18.0+cpu\n",
            "torch version: 2.3.0+cpu\n"
          ]
        }
      ],
      "source": [
        "# prompt: print versions\n",
        "\n",
        "print('torchtext version:', torchtext.__version__)\n",
        "print('torch version:', torch.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'g:\\\\CampusX\\\\Onsite Projects\\\\Pytorch-NMT\\\\Neural_Machine_Translation\\\\Eng_to_Urdu_Translation'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cd \"notebooks\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPALHpsv_nYV",
        "outputId": "53ef2335-8357-489c-d2a5-36d84dbeafad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['English', 'Urdu'], dtype='object')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "df = pd.read_csv(r'G:\\CampusX\\Onsite Projects\\Pytorch-NMT\\Neural_Machine_Translation\\Eng_to_Urdu_Translation\\data\\eng-to-Urdu-pairs\\English_Urdu_pairs.csv')\n",
        "\n",
        "df.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pZP1RF-0Af6y"
      },
      "outputs": [],
      "source": [
        "df[['English']].to_csv(r'G:\\CampusX\\Onsite Projects\\Pytorch-NMT\\Neural_Machine_Translation\\Eng_to_Urdu_Translation\\data\\english\\english.csv', index=False)\n",
        "df[['Urdu']].to_csv(r'G:\\CampusX\\Onsite Projects\\Pytorch-NMT\\Neural_Machine_Translation\\Eng_to_Urdu_Translation\\data\\urdu\\urdu.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "SYiAWp0p7CHh"
      },
      "outputs": [],
      "source": [
        "en_filepath = r'G:\\CampusX\\Onsite Projects\\Pytorch-NMT\\Neural_Machine_Translation\\Eng_to_Urdu_Translation\\data\\english\\english.csv'\n",
        "ur_filepath = r'G:\\CampusX\\Onsite Projects\\Pytorch-NMT\\Neural_Machine_Translation\\Eng_to_Urdu_Translation\\data\\urdu\\urdu.csv'\n",
        "\n",
        "with open(en_filepath, \"r\", encoding='utf-8') as f:\n",
        "  english_data = f.readlines()\n",
        "\n",
        "with open(ur_filepath, \"r\", encoding='utf-8') as f:\n",
        "  urdu_data = f.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lh2xNNf3A8Vx",
        "outputId": "4e0598a4-7e50-44b1-807d-1642c9af3250"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English data: 26873\n",
            "Urdu data: 26872\n"
          ]
        }
      ],
      "source": [
        "print(f\"English data: {len(english_data)}\")\n",
        "print(f\"Urdu data: {len(urdu_data)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "vHq9uIt47tMw"
      },
      "outputs": [],
      "source": [
        "req_urdu = urdu_data[1:26860]\n",
        "req_english = english_data[1:26860]\n",
        "data = {\"english_txt\":req_english,\"urdu_txt\":req_urdu}\n",
        "\n",
        "df = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "A8y1hR9YHvuU",
        "outputId": "a51ba69e-f369-46b3-9080-e592d75e781f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_txt</th>\n",
              "      <th>urdu_txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24592</th>\n",
              "      <td>you are very funny\\n</td>\n",
              "      <td>تم مذاحیہ ہو!\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6868</th>\n",
              "      <td>he is aggressive\\n</td>\n",
              "      <td>وہ جارحانہ ہے\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13047</th>\n",
              "      <td>Can you recommend a good place to eat?\\n</td>\n",
              "      <td>کیا آپ کوئی اچھا کھانے کی جگہ تجویز کر سکتے ہی...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19880</th>\n",
              "      <td>are you sick of me\\n</td>\n",
              "      <td>کیا آپ مجھ سے بیمار ہیں؟\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20735</th>\n",
              "      <td>how was your day\\n</td>\n",
              "      <td>آپ کا دن کیسا گزرا\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    english_txt  \\\n",
              "24592                      you are very funny\\n   \n",
              "6868                         he is aggressive\\n   \n",
              "13047  Can you recommend a good place to eat?\\n   \n",
              "19880                      are you sick of me\\n   \n",
              "20735                        how was your day\\n   \n",
              "\n",
              "                                                urdu_txt  \n",
              "24592                                    تم مذاحیہ ہو!\\n  \n",
              "6868                                     وہ جارحانہ ہے\\n  \n",
              "13047  کیا آپ کوئی اچھا کھانے کی جگہ تجویز کر سکتے ہی...  \n",
              "19880                         کیا آپ مجھ سے بیمار ہیں؟\\n  \n",
              "20735                               آپ کا دن کیسا گزرا\\n  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9P328zXECp7",
        "outputId": "31ff316e-a085-4cdf-f525-dbd2dd6a0891"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(26859, 2)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oc2KEb5EPzz",
        "outputId": "b920df74-37cc-4d64-c3c2-2deb9e258b92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['english_txt', 'urdu_txt'], dtype='object')"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "CLMBsn9M_Bo0"
      },
      "outputs": [],
      "source": [
        "# Handling the encoding issue by removing the rows.\n",
        "\n",
        "def is_urdu_corrupted(text):\n",
        "    \"\"\"\n",
        "    Checks if a given text contains characters outside the typical Urdu script range.\n",
        "\n",
        "    Args:\n",
        "        text (str): The text to be checked.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the text contains characters outside the Urdu range, False otherwise.\n",
        "    \"\"\"\n",
        "    if re.search(r'[^\\u0900-\\u097F\\s,.?!\\u0600-\\u06FF]', text):  # Expanded range for punctuation\n",
        "        return True  # Text contains characters outside Urdu range\n",
        "    return False  # Text is likely within Urdu range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "IzYiEZRnHg0E"
      },
      "outputs": [],
      "source": [
        "# Apply the function to the 'Hindi' column to create a mask\n",
        "df['Corrupted'] = df['urdu_txt'].apply(is_urdu_corrupted)\n",
        "\n",
        "# Filter out corrupted rows\n",
        "df_clean = df[~df['Corrupted']]\n",
        "\n",
        "# Drop the 'Corrupted' column as it's no longer needed\n",
        "df_clean = df_clean.drop(columns=['Corrupted'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMKkHxG9Hspq",
        "outputId": "d1afeceb-6661-466f-ac86-0287c2b74192"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(26727, 2)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_clean.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tat5A0XYF3A9",
        "outputId": "77e68143-573e-44f9-ae92-6e658c0f5649"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['english_txt', 'urdu_txt'], dtype='object')"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_clean.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "-kq-NSH9yvuy"
      },
      "outputs": [],
      "source": [
        "def clean_text(text, language=\"english\"):\n",
        "    # Normalize unicode characters\n",
        "    text = unicodedata.normalize('NFKC', text)\n",
        "    # Convert to lowercase if the text is in English\n",
        "    if language == \"english\":\n",
        "        text = text.lower()\n",
        "    # Remove any English words present in Urdu text.\n",
        "    if language == \"urdu\":\n",
        "        text = re.sub('[a-zA-Z]', '', text)\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    # Remove punctuations\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "h-uvkUye8g8o"
      },
      "outputs": [],
      "source": [
        "df_clean[\"english_txt\"] = df_clean[\"english_txt\"].apply(clean_text)\n",
        "df_clean[\"urdu_txt\"] = df_clean['urdu_txt'].apply(clean_text, args=(\"urdu\",))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "nKFtG_obLh84",
        "outputId": "2ca671db-8f5f-4683-a2b9-7c1bf44d53f5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_txt</th>\n",
              "      <th>urdu_txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8699</th>\n",
              "      <td>i have no future</td>\n",
              "      <td>میرا کوئی مستقبل نہیں ہے</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22057</th>\n",
              "      <td>materials</td>\n",
              "      <td>مواد</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7046</th>\n",
              "      <td>have fun this summer</td>\n",
              "      <td>اس موسم گرما میں مزہ کریں</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5323</th>\n",
              "      <td>you cant help me</td>\n",
              "      <td>تم میری مدد نہیں کر سکتے</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10193</th>\n",
              "      <td>opinion</td>\n",
              "      <td>رائے</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10051</th>\n",
              "      <td>public opinion</td>\n",
              "      <td>عوامی رائے</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26551</th>\n",
              "      <td>you have not done anything so far</td>\n",
              "      <td>غور سے سنیں کہ کیا کرنے کی ضرورت ہے</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11059</th>\n",
              "      <td>do you eat out often</td>\n",
              "      <td>کیا آپ اکثر باہر کھاتے ہیں</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21956</th>\n",
              "      <td>please step inside</td>\n",
              "      <td>براہ کرم اندر قدم رکھیں</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13774</th>\n",
              "      <td>he loves to gossip</td>\n",
              "      <td>وہ گپ شپ سے محبت کرتا ہے</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             english_txt                             urdu_txt\n",
              "8699                    i have no future             میرا کوئی مستقبل نہیں ہے\n",
              "22057                          materials                                 مواد\n",
              "7046                have fun this summer            اس موسم گرما میں مزہ کریں\n",
              "5323                    you cant help me             تم میری مدد نہیں کر سکتے\n",
              "10193                            opinion                                 رائے\n",
              "10051                     public opinion                           عوامی رائے\n",
              "26551  you have not done anything so far  غور سے سنیں کہ کیا کرنے کی ضرورت ہے\n",
              "11059               do you eat out often           کیا آپ اکثر باہر کھاتے ہیں\n",
              "21956                 please step inside              براہ کرم اندر قدم رکھیں\n",
              "13774                 he loves to gossip             وہ گپ شپ سے محبت کرتا ہے"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_clean.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "5-j5YrNJLxid"
      },
      "outputs": [],
      "source": [
        "df_clean['English_Words'] = df_clean['english_txt'].apply(lambda x: len(x.split()))\n",
        "df_clean['Urdu_Words'] = df_clean['urdu_txt'].apply(lambda x: len(x.split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "NpOd55hIL7DA",
        "outputId": "8bcbcdbc-fba9-4ef0-f81f-4ed7b9df2a92"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Calculate averages\n",
        "average_english_words = df_clean['English_Words'].quantile(.99)\n",
        "average_hindi_words = df_clean['Urdu_Words'].quantile(.99)\n",
        "\n",
        "# Data for plotting\n",
        "averages = [average_english_words, average_hindi_words]\n",
        "languages = ['English', 'Urdu']\n",
        "\n",
        "# Creating the plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(languages, averages, color=['blue', 'red'])\n",
        "plt.xlabel('Language')\n",
        "plt.ylabel('Number of Words per Sentence')\n",
        "plt.title('Comparison of Number of Words Counts in English and Urdu')\n",
        "plt.ylim(0, max(averages) + 1)  # Adjust y-axis for better visualization\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIFPGpu36sSl"
      },
      "source": [
        "# Torchtext\n",
        "Torchtext is a library within the PyTorch ecosystem designed to facilitate the preprocessing of textual data.\n",
        "\n",
        "## get_tokenizer\n",
        ". The get_tokenizer function is one of the core utilities provided by torchtext for tokenizing text data.\n",
        "\n",
        ". get_tokenizer retrieves a tokenizer function based on the method specified. This tokenizer can then be used to convert strings of text into lists of tokens.\n",
        "##Parameters\n",
        "  \n",
        "  tokenizer: This argument specifies the type of tokenizer to use. You can specify built-in tokenizers such as \"basic_english\", \"spacy\", \"moses\", or even provide a custom tokenizer function.\n",
        "\n",
        "  language: Some tokenizers, like those based on the Moses or Spacy libraries, might require you to specify the language of the text, which influences how the text is tokenized (e.g., handling language-specific punctuation and splitting rules)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMW-FGHFHdDz",
        "outputId": "839ea3ea-3de7-4467-c015-de1cf57300fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word Tokens: ['زین', 'میری', 'طرف', 'دیکھ', 'رہا', 'ہے']\n"
          ]
        }
      ],
      "source": [
        "import indicnlp\n",
        "trivial_tokenize_urdu\n",
        "# Sample Urdu sentence\n",
        "urdu_text = \"زین میری طرف دیکھ رہا ہے\"\n",
        "\n",
        "# Tokenizing into words\n",
        "word_tokens = indicnlp.tokenize.indic_tokenize.trivial_tokenize_urdu(urdu_text)\n",
        "print(\"Word Tokens:\", word_tokens)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shV-tSQmMO-Q",
        "outputId": "7a10c7f6-c1e1-4d62-f9d0-681e6b338fdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence Tokens: ['زین میری طرف دیکھ رہا ہے۔ یہ ایک خوبصورت دن ہے۔']\n"
          ]
        }
      ],
      "source": [
        "# If you have multiple sentences, you can also tokenize into sentences\n",
        "# Example with multiple sentences\n",
        "urdu_text_multi = \"زین میری طرف دیکھ رہا ہے۔ یہ ایک خوبصورت دن ہے۔\"\n",
        "sentence_tokens = indicnlp.tokenize.sentence_tokenize.sentence_split(urdu_text_multi, lang='hi')\n",
        "print(\"Sentence Tokens:\", sentence_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "SzBeCo8MOcwE"
      },
      "outputs": [],
      "source": [
        "tokenizer_eng = get_tokenizer('basic_english')\n",
        "tokenizer_urd = trivial_tokenize_urdu # This is the Hindi(Urdu) tokenizer from Indic NLP\n",
        "\n",
        "tokenized_english_txt = [tokenizer_eng(english_sen) for english_sen in df_clean['english_txt'] ]\n",
        "tokenized_urdu_txt = [tokenizer_urd(urdu_sen) for urdu_sen in df_clean['urdu_txt'] ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khwzrttoOFjp",
        "outputId": "92cc6e89-712a-4b12-a224-fb58f7281d07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['it', 'was', 'cold']\n",
            "['یہ', 'ٹھنڈا', 'تھا']\n"
          ]
        }
      ],
      "source": [
        "print(tokenized_english_txt[44])\n",
        "print(tokenized_urdu_txt[44])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4TytNjp6xKC"
      },
      "source": [
        "## build_vocab_from_iterator\n",
        "`build_vocab_from_iterator` function in the torchtext.vocab module is used to create a vocabulary from an iterable of tokenized data. This vocabulary is essential for converting textual data into numerical form.\n",
        "\n",
        "#Parameters:\n",
        "##tokenized_conv (iterator):\n",
        "This is the main data input to the function. It should be an iterator (like a `generator` or a `list`) that yields sequences of tokens. Each sequence represents a document or an example in your dataset.\n",
        "##min_freq (int, optional):\n",
        " This parameter specifies the minimum frequency a token must have to be included in the vocabulary. Tokens that appear fewer than min_freq times are excluded from the vocabulary. This is useful for removing rare words which might be typos or irrelevant to most analyses.\n",
        "##specials (list of str, optional):\n",
        " This is a list of special tokens that you want to add to the vocabulary. Common special tokens include:\n",
        "'<pad>': A padding token used to equalize the lengths of sequences.\n",
        "'<oov>' (or '<unk>' for \"unknown\"): A token used to represent out-of-vocabulary words during inference, or when a word appears that is not in the training vocabulary.\n",
        "##special_first (bool, optional):\n",
        " Determines the ordering of special tokens in the vocabulary. If True, special tokens are added at the beginning of the vocabulary. This can be helpful for certain models where token indices are significant (e.g., models using embedding layers might have specific handling for lower indices)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "upBTp-UJS9xC"
      },
      "outputs": [],
      "source": [
        "# Step 3: Building Vocabulary\n",
        "features_vocab = torchtext.vocab.build_vocab_from_iterator(tokenized_english_txt, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
        "target_vocab = torchtext.vocab.build_vocab_from_iterator(tokenized_urdu_txt, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
        "\n",
        "features_vocab.set_default_index(features_vocab['<unk>'])\n",
        "target_vocab.set_default_index(target_vocab['<unk>'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "CkkIj_XFLjWw"
      },
      "outputs": [],
      "source": [
        "features_vocab_total_words = len(features_vocab)\n",
        "target_vocab_total_words = len(target_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5bIQHZuJXMS",
        "outputId": "ce7252e2-59ad-4bc8-841f-dd21095e7776"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6427\n",
            "6021\n"
          ]
        }
      ],
      "source": [
        "print(features_vocab_total_words)  #English\n",
        "print(target_vocab_total_words)    #Hindi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttQaYjVnpOh1",
        "outputId": "2a4c7a16-9038-4fc7-8039-8cd4f79b0efe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features_vocab['<bos>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnTdkafdLmNO",
        "outputId": "070deba8-c1e3-4428-fb79-a0cdd6ce65de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6427\n",
            "6021\n"
          ]
        }
      ],
      "source": [
        "print(features_vocab_total_words)\n",
        "print(target_vocab_total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "uvUtpWeDLt_g"
      },
      "outputs": [],
      "source": [
        "def tokens_to_indices(tokenized_texts, vocab):\n",
        "    indices_texts = []\n",
        "    for sentence in tokenized_texts:\n",
        "        indices_texts.append([vocab[token] for token in sentence if token in vocab])\n",
        "    return indices_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "t1pH9g5XM-Nf"
      },
      "outputs": [],
      "source": [
        "english_indices = tokens_to_indices(tokenized_english_txt, features_vocab)\n",
        "urdu_indices = tokens_to_indices(tokenized_urdu_txt, target_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZMYCBAxJ-aB",
        "outputId": "50f7d94a-7e7d-40f5-b310-2ecc8b7f36ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[9, 5944, 112, 139],\n",
              " [337, 55, 263, 12],\n",
              " [36, 5, 12],\n",
              " [29, 346],\n",
              " [4, 363, 16, 356]]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "english_indices[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Ohf0O1CnM-Qf"
      },
      "outputs": [],
      "source": [
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, english_data, urdu_data):\n",
        "        self.english_data = english_data\n",
        "        self.urdu_data = urdu_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.english_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        english = torch.tensor(self.english_data[idx], dtype=torch.long)\n",
        "        urdu = torch.tensor(self.urdu_data[idx], dtype=torch.long)\n",
        "        return english, urdu\n",
        "\n",
        "# Create the custom dataset\n",
        "dataset = TranslationDataset(english_indices, urdu_indices)\n",
        "FIXED_LENGTH = 60  # or any appropriate length based on your data or model requirements\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TP8Dy_V67dyj"
      },
      "source": [
        "##Purpose of collate_fn\n",
        "The primary purpose of `collate_fn` is to dynamically decide how to combine multiple data samples into a single batch. Data samples can be anything from images, texts, or other forms of data, and they might not naturally fit together in a straightforward way (e.g., texts of varying lengths)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "KBEn7e-NcxkF"
      },
      "outputs": [],
      "source": [
        "def collate_batch(batch):\n",
        "    english_batch, urdu_batch = zip(*batch)\n",
        "\n",
        "    # Pad or truncate English batch\n",
        "    english_batch = [torch.tensor(seq[:FIXED_LENGTH], dtype=torch.long) if len(seq) > FIXED_LENGTH\n",
        "                     else torch.cat([torch.tensor(seq, dtype=torch.long),\n",
        "                                    torch.full((FIXED_LENGTH - len(seq),), features_vocab['<pad>'], dtype=torch.long)])\n",
        "                     for seq in english_batch]\n",
        "\n",
        "    # Pad or truncate Hindi batch\n",
        "    urdu_batch = [torch.tensor(seq[:FIXED_LENGTH], dtype=torch.long) if len(seq) > FIXED_LENGTH\n",
        "                  else torch.cat([torch.tensor(seq, dtype=torch.long),\n",
        "                                 torch.full((FIXED_LENGTH - len(seq),), target_vocab['<pad>'], dtype=torch.long)])\n",
        "                  for seq in urdu_batch]\n",
        "\n",
        "    # Pad sequences within the batch to the maximum length\n",
        "    # Use pad_sequence instead of stack to handle variable length sequences\n",
        "    english_batch = torch.nn.utils.rnn.pad_sequence(english_batch, batch_first=True, padding_value=features_vocab['<pad>'])\n",
        "    urdu_batch = torch.nn.utils.rnn.pad_sequence(urdu_batch, batch_first=True, padding_value=target_vocab['<pad>'])\n",
        "\n",
        "    return english_batch, urdu_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "TDhltO-xc1zM"
      },
      "outputs": [],
      "source": [
        "batch_size = 32  # Adjust the batch size as needed\n",
        "train_dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate_batch, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "bs67MOd8achu"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wytwBPlbV0Sk",
        "outputId": "ad56acf9-28bc-416f-9231-43fab3482ff9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D7ndzj28Siv",
        "outputId": "c107e613-c25d-42cc-fc1e-8d3ecda9df70"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-54-f75d71704b9d>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  else torch.cat([torch.tensor(seq, dtype=torch.long),\n",
            "<ipython-input-54-f75d71704b9d>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  else torch.cat([torch.tensor(seq, dtype=torch.long),\n"
          ]
        }
      ],
      "source": [
        "sample = next(iter(train_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMf18HtM8X0q",
        "outputId": "9a372b45-60a0-4a97-fbd6-910f38d4c772"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 60])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample[0].size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFD66slv7OYw"
      },
      "source": [
        "`get_itos`: stands for \"index-to-string\". The method returns a list where the indices in the list correspond to the numerical indices used in your model, and the values at those indices are the actual string representations (tokens)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "aUv5MU5RM-UG"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):    #[4,8,9,15,12]\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded)\n",
        "        return output, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LcVKzJszWK2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "SOZQffs_aOrQ"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)   # Transform for query\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size)   # Transform for keys\n",
        "        self.Va = nn.Linear(hidden_size, 1)   # Compute the attention score\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        # Expand query to match keys' batch and sequence dimension\n",
        "        # Encoder Output i.e key Shape (batch, seq_len, hidden_dim) when batch_first = True\n",
        "        # Hidden State of Decoder i.e query shape (num_dir*num_layers, batch, hidden_dim)\n",
        "\n",
        "        # Since Decoder Queries about the information to encoder on which token to focus when generating the current token\n",
        "        # we need to replecate the decoder Hidden State along the encoder output to get score for each output.\n",
        "        key_shape = keys.size()\n",
        "\n",
        "        query = query.repeat(1, key_shape[1], 1)\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))  # attn_score = VT.(tanh(Wa*s|encoder + Ua|decoder + bias))\n",
        "        scores = scores.squeeze(-1)\n",
        "\n",
        "        weights = torch.softmax(scores, dim=1)\n",
        "        weights = weights.unsqueeze(1)\n",
        "        context = torch.bmm(weights, keys)\n",
        "\n",
        "        return context, weights\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "\n",
        "        bos_token_index = features_vocab['<bos>']\n",
        "        decoder_input = torch.full((batch_size, 1), bos_token_index, dtype=torch.long, device=device)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "        # fixed length set to 60\n",
        "        for i in range(60):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        embedded =  self.dropout(self.embedding(input))\n",
        "\n",
        "        query = hidden.permute(1, 0, 2)    # this is the shape of [num_layers * num_directions, batch_size, hidden_size]\n",
        "                                            # encoder output [batch_size, seq_len, hidden_size]\n",
        "        context, attn_weights = self.attention(query, encoder_outputs)\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden, attn_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "I53ihZ7Jfiab"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QxGYeB_XVKwM",
        "outputId": "387499f5-7145-4b53-ac23-902f65f0e637"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'g:\\\\CampusX\\\\Onsite Projects\\\\Pytorch-NMT\\\\Neural_Machine_Translation\\\\Eng_to_Urdu_Translation'"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "uHBcirVDfidT"
      },
      "outputs": [],
      "source": [
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=5, plot_every=5, save_every=5, save_path = r\"Eng_to_Urdu_Translation\\data\\trained_models\"):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, epoch) # Pass epoch to train_epoch\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "        if epoch % save_every == 0:\n",
        "            encoder_save_path = os.path.join(save_path, r'Eng_to_Urdu_Translation\\data\\urdu\\NML_EngtoUrdu_params\\encoder_epochs\\encoder_epoch_{}.pth'.format(epoch))\n",
        "            decoder_save_path = os.path.join(save_path, r'Eng_to_Urdu_Translation\\data\\urdu\\NML_EngtoUrdu_params\\decoder_epochs\\decoder_epoch_{}.pth'.format(epoch))\n",
        "            torch.save(encoder.state_dict(), encoder_save_path)\n",
        "            torch.save(decoder.state_dict(), decoder_save_path)\n",
        "            print(f'Model saved at epoch {epoch}')\n",
        "    showPlot(plot_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "rzuTOQJ8ffI4"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "E96KOEbPfW1T"
      },
      "outputs": [],
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "          decoder_optimizer, criterion, epoch): # Add epoch as argument\n",
        "\n",
        "    total_loss = 0\n",
        "    for i, data in enumerate(dataloader):  # Get batch index\n",
        "        input_tensor, target_tensor = data\n",
        "        input_tensor, target_tensor = input_tensor.to(device), target_tensor.to(device)\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Print progress within the epoch\n",
        "        if (i+1) % 100 == 0:  # Print every 10 batches\n",
        "            print(f\"Epoch {epoch+1}, Batch {i+1}/{len(dataloader)}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "E3J8fUnzfiHK"
      },
      "outputs": [],
      "source": [
        "hidden_size = 256\n",
        "batch_size = 32\n",
        "features_vocab_total_words = len(features_vocab)\n",
        "target_vocab_total_words = len(target_vocab)\n",
        "\n",
        "encoder = EncoderRNN(features_vocab_total_words, hidden_size).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, target_vocab_total_words).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNAVKmc3jxWf",
        "outputId": "9e138f12-71b7-4be9-e23f-e85b8a3d0326"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-39-f75d71704b9d>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  else torch.cat([torch.tensor(seq, dtype=torch.long),\n",
            "<ipython-input-39-f75d71704b9d>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  else torch.cat([torch.tensor(seq, dtype=torch.long),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Batch 100/836, Loss: 0.4807\n",
            "Epoch 2, Batch 200/836, Loss: 0.4593\n",
            "Epoch 2, Batch 300/836, Loss: 0.4372\n",
            "Epoch 2, Batch 400/836, Loss: 0.3992\n",
            "Epoch 2, Batch 500/836, Loss: 0.4110\n",
            "Epoch 2, Batch 600/836, Loss: 0.3981\n",
            "Epoch 2, Batch 700/836, Loss: 0.3402\n",
            "Epoch 2, Batch 800/836, Loss: 0.3293\n",
            "Epoch 3, Batch 100/836, Loss: 0.2755\n",
            "Epoch 3, Batch 200/836, Loss: 0.3131\n",
            "Epoch 3, Batch 300/836, Loss: 0.3460\n",
            "Epoch 3, Batch 400/836, Loss: 0.2579\n",
            "Epoch 3, Batch 500/836, Loss: 0.2443\n",
            "Epoch 3, Batch 600/836, Loss: 0.2498\n",
            "Epoch 3, Batch 700/836, Loss: 0.2519\n",
            "Epoch 3, Batch 800/836, Loss: 0.2823\n",
            "Epoch 4, Batch 100/836, Loss: 0.1905\n",
            "Epoch 4, Batch 200/836, Loss: 0.1816\n",
            "Epoch 4, Batch 300/836, Loss: 0.2297\n",
            "Epoch 4, Batch 400/836, Loss: 0.2432\n",
            "Epoch 4, Batch 500/836, Loss: 0.2026\n",
            "Epoch 4, Batch 600/836, Loss: 0.2947\n",
            "Epoch 4, Batch 700/836, Loss: 0.2442\n",
            "Epoch 4, Batch 800/836, Loss: 0.2166\n",
            "Epoch 5, Batch 100/836, Loss: 0.1839\n",
            "Epoch 5, Batch 200/836, Loss: 0.1615\n",
            "Epoch 5, Batch 300/836, Loss: 0.2028\n",
            "Epoch 5, Batch 400/836, Loss: 0.2118\n",
            "Epoch 5, Batch 500/836, Loss: 0.1499\n",
            "Epoch 5, Batch 600/836, Loss: 0.2047\n",
            "Epoch 5, Batch 700/836, Loss: 0.1734\n",
            "Epoch 5, Batch 800/836, Loss: 0.1676\n",
            "Epoch 6, Batch 100/836, Loss: 0.1406\n",
            "Epoch 6, Batch 200/836, Loss: 0.1111\n",
            "Epoch 6, Batch 300/836, Loss: 0.1364\n",
            "Epoch 6, Batch 400/836, Loss: 0.1442\n",
            "Epoch 6, Batch 500/836, Loss: 0.1184\n",
            "Epoch 6, Batch 600/836, Loss: 0.1361\n",
            "Epoch 6, Batch 700/836, Loss: 0.1119\n",
            "Epoch 6, Batch 800/836, Loss: 0.1532\n",
            "9m 40s (- 87m 2s) (5 10%) 0.2572\n",
            "Model saved at epoch 5\n",
            "Epoch 7, Batch 100/836, Loss: 0.1029\n",
            "Epoch 7, Batch 200/836, Loss: 0.1097\n",
            "Epoch 7, Batch 300/836, Loss: 0.1111\n",
            "Epoch 7, Batch 400/836, Loss: 0.0928\n",
            "Epoch 7, Batch 500/836, Loss: 0.1670\n",
            "Epoch 7, Batch 600/836, Loss: 0.1588\n",
            "Epoch 7, Batch 700/836, Loss: 0.1020\n",
            "Epoch 7, Batch 800/836, Loss: 0.1112\n",
            "Epoch 8, Batch 100/836, Loss: 0.0645\n",
            "Epoch 8, Batch 200/836, Loss: 0.0663\n",
            "Epoch 8, Batch 300/836, Loss: 0.0697\n",
            "Epoch 8, Batch 400/836, Loss: 0.0879\n",
            "Epoch 8, Batch 500/836, Loss: 0.0727\n",
            "Epoch 8, Batch 600/836, Loss: 0.1421\n",
            "Epoch 8, Batch 700/836, Loss: 0.1013\n",
            "Epoch 8, Batch 800/836, Loss: 0.1011\n",
            "Epoch 9, Batch 100/836, Loss: 0.0583\n",
            "Epoch 9, Batch 200/836, Loss: 0.0821\n",
            "Epoch 9, Batch 300/836, Loss: 0.0618\n",
            "Epoch 9, Batch 400/836, Loss: 0.0583\n",
            "Epoch 9, Batch 500/836, Loss: 0.0672\n",
            "Epoch 9, Batch 600/836, Loss: 0.0988\n",
            "Epoch 9, Batch 700/836, Loss: 0.0639\n",
            "Epoch 9, Batch 800/836, Loss: 0.0953\n",
            "Epoch 10, Batch 100/836, Loss: 0.0414\n",
            "Epoch 10, Batch 200/836, Loss: 0.0318\n",
            "Epoch 10, Batch 300/836, Loss: 0.0742\n",
            "Epoch 10, Batch 400/836, Loss: 0.0464\n",
            "Epoch 10, Batch 500/836, Loss: 0.0513\n",
            "Epoch 10, Batch 600/836, Loss: 0.0467\n",
            "Epoch 10, Batch 700/836, Loss: 0.0715\n",
            "Epoch 10, Batch 800/836, Loss: 0.0807\n",
            "Epoch 11, Batch 100/836, Loss: 0.0494\n",
            "Epoch 11, Batch 200/836, Loss: 0.0661\n",
            "Epoch 11, Batch 300/836, Loss: 0.0314\n",
            "Epoch 11, Batch 400/836, Loss: 0.0490\n",
            "Epoch 11, Batch 500/836, Loss: 0.0393\n",
            "Epoch 11, Batch 600/836, Loss: 0.0575\n",
            "Epoch 11, Batch 700/836, Loss: 0.0627\n",
            "Epoch 11, Batch 800/836, Loss: 0.0567\n",
            "18m 53s (- 75m 34s) (10 20%) 0.0745\n",
            "Model saved at epoch 10\n",
            "Epoch 12, Batch 100/836, Loss: 0.0395\n",
            "Epoch 12, Batch 200/836, Loss: 0.0225\n",
            "Epoch 12, Batch 300/836, Loss: 0.0344\n",
            "Epoch 12, Batch 400/836, Loss: 0.0327\n",
            "Epoch 12, Batch 500/836, Loss: 0.0370\n",
            "Epoch 12, Batch 600/836, Loss: 0.0391\n",
            "Epoch 12, Batch 700/836, Loss: 0.0308\n",
            "Epoch 12, Batch 800/836, Loss: 0.0402\n",
            "Epoch 13, Batch 100/836, Loss: 0.0275\n",
            "Epoch 13, Batch 200/836, Loss: 0.0336\n",
            "Epoch 13, Batch 300/836, Loss: 0.0399\n",
            "Epoch 13, Batch 400/836, Loss: 0.0358\n",
            "Epoch 13, Batch 500/836, Loss: 0.0333\n",
            "Epoch 13, Batch 600/836, Loss: 0.0275\n",
            "Epoch 13, Batch 700/836, Loss: 0.0501\n",
            "Epoch 13, Batch 800/836, Loss: 0.0508\n",
            "Epoch 14, Batch 100/836, Loss: 0.0243\n",
            "Epoch 14, Batch 200/836, Loss: 0.0441\n",
            "Epoch 14, Batch 300/836, Loss: 0.0375\n",
            "Epoch 14, Batch 400/836, Loss: 0.0230\n",
            "Epoch 14, Batch 500/836, Loss: 0.0346\n",
            "Epoch 14, Batch 600/836, Loss: 0.0247\n",
            "Epoch 14, Batch 700/836, Loss: 0.0232\n",
            "Epoch 14, Batch 800/836, Loss: 0.0538\n",
            "Epoch 15, Batch 100/836, Loss: 0.0220\n",
            "Epoch 15, Batch 200/836, Loss: 0.0208\n",
            "Epoch 15, Batch 300/836, Loss: 0.0356\n",
            "Epoch 15, Batch 400/836, Loss: 0.0318\n",
            "Epoch 15, Batch 500/836, Loss: 0.0216\n",
            "Epoch 15, Batch 600/836, Loss: 0.0416\n",
            "Epoch 15, Batch 700/836, Loss: 0.0287\n",
            "Epoch 15, Batch 800/836, Loss: 0.0202\n",
            "Epoch 16, Batch 100/836, Loss: 0.0217\n",
            "Epoch 16, Batch 200/836, Loss: 0.0177\n",
            "Epoch 16, Batch 300/836, Loss: 0.0233\n",
            "Epoch 16, Batch 400/836, Loss: 0.0139\n",
            "Epoch 16, Batch 500/836, Loss: 0.0194\n",
            "Epoch 16, Batch 600/836, Loss: 0.0277\n",
            "Epoch 16, Batch 700/836, Loss: 0.0173\n",
            "Epoch 16, Batch 800/836, Loss: 0.0260\n",
            "28m 5s (- 65m 33s) (15 30%) 0.0304\n",
            "Model saved at epoch 15\n",
            "Epoch 17, Batch 100/836, Loss: 0.0175\n",
            "Epoch 17, Batch 200/836, Loss: 0.0141\n",
            "Epoch 17, Batch 300/836, Loss: 0.0156\n",
            "Epoch 17, Batch 400/836, Loss: 0.0160\n",
            "Epoch 17, Batch 500/836, Loss: 0.0215\n",
            "Epoch 17, Batch 600/836, Loss: 0.0248\n",
            "Epoch 17, Batch 700/836, Loss: 0.0272\n",
            "Epoch 17, Batch 800/836, Loss: 0.0211\n",
            "Epoch 18, Batch 100/836, Loss: 0.0148\n",
            "Epoch 18, Batch 200/836, Loss: 0.0299\n",
            "Epoch 18, Batch 300/836, Loss: 0.0172\n",
            "Epoch 18, Batch 400/836, Loss: 0.0222\n",
            "Epoch 18, Batch 500/836, Loss: 0.0168\n",
            "Epoch 18, Batch 600/836, Loss: 0.0211\n",
            "Epoch 18, Batch 700/836, Loss: 0.0205\n",
            "Epoch 18, Batch 800/836, Loss: 0.0188\n",
            "Epoch 19, Batch 100/836, Loss: 0.0150\n",
            "Epoch 19, Batch 200/836, Loss: 0.0167\n",
            "Epoch 19, Batch 300/836, Loss: 0.0126\n",
            "Epoch 19, Batch 400/836, Loss: 0.0270\n",
            "Epoch 19, Batch 500/836, Loss: 0.0171\n",
            "Epoch 19, Batch 600/836, Loss: 0.0235\n",
            "Epoch 19, Batch 700/836, Loss: 0.0194\n",
            "Epoch 19, Batch 800/836, Loss: 0.0210\n",
            "Epoch 20, Batch 100/836, Loss: 0.0206\n",
            "Epoch 20, Batch 200/836, Loss: 0.0141\n",
            "Epoch 20, Batch 300/836, Loss: 0.0128\n",
            "Epoch 20, Batch 400/836, Loss: 0.0152\n",
            "Epoch 20, Batch 500/836, Loss: 0.0203\n",
            "Epoch 20, Batch 600/836, Loss: 0.0218\n",
            "Epoch 20, Batch 700/836, Loss: 0.0224\n",
            "Epoch 20, Batch 800/836, Loss: 0.0234\n",
            "Epoch 21, Batch 100/836, Loss: 0.0107\n",
            "Epoch 21, Batch 200/836, Loss: 0.0130\n",
            "Epoch 21, Batch 300/836, Loss: 0.0201\n",
            "Epoch 21, Batch 400/836, Loss: 0.0199\n",
            "Epoch 21, Batch 500/836, Loss: 0.0118\n",
            "Epoch 21, Batch 600/836, Loss: 0.0103\n",
            "Epoch 21, Batch 700/836, Loss: 0.0189\n",
            "Epoch 21, Batch 800/836, Loss: 0.0149\n",
            "37m 15s (- 55m 53s) (20 40%) 0.0177\n",
            "Model saved at epoch 20\n",
            "Epoch 22, Batch 100/836, Loss: 0.0082\n",
            "Epoch 22, Batch 200/836, Loss: 0.0099\n",
            "Epoch 22, Batch 300/836, Loss: 0.0082\n",
            "Epoch 22, Batch 400/836, Loss: 0.0152\n",
            "Epoch 22, Batch 500/836, Loss: 0.0145\n",
            "Epoch 22, Batch 600/836, Loss: 0.0112\n",
            "Epoch 22, Batch 700/836, Loss: 0.0138\n",
            "Epoch 22, Batch 800/836, Loss: 0.0249\n",
            "Epoch 23, Batch 100/836, Loss: 0.0129\n",
            "Epoch 23, Batch 200/836, Loss: 0.0104\n",
            "Epoch 23, Batch 300/836, Loss: 0.0090\n",
            "Epoch 23, Batch 400/836, Loss: 0.0153\n",
            "Epoch 23, Batch 500/836, Loss: 0.0148\n",
            "Epoch 23, Batch 600/836, Loss: 0.0160\n",
            "Epoch 23, Batch 700/836, Loss: 0.0109\n",
            "Epoch 23, Batch 800/836, Loss: 0.0170\n",
            "Epoch 24, Batch 100/836, Loss: 0.0172\n",
            "Epoch 24, Batch 200/836, Loss: 0.0110\n",
            "Epoch 24, Batch 300/836, Loss: 0.0096\n",
            "Epoch 24, Batch 400/836, Loss: 0.0102\n",
            "Epoch 24, Batch 500/836, Loss: 0.0099\n",
            "Epoch 24, Batch 600/836, Loss: 0.0134\n",
            "Epoch 24, Batch 700/836, Loss: 0.0136\n",
            "Epoch 24, Batch 800/836, Loss: 0.0151\n",
            "Epoch 25, Batch 100/836, Loss: 0.0101\n",
            "Epoch 25, Batch 200/836, Loss: 0.0095\n",
            "Epoch 25, Batch 300/836, Loss: 0.0080\n",
            "Epoch 25, Batch 400/836, Loss: 0.0123\n",
            "Epoch 25, Batch 500/836, Loss: 0.0139\n",
            "Epoch 25, Batch 600/836, Loss: 0.0200\n",
            "Epoch 25, Batch 700/836, Loss: 0.0209\n",
            "Epoch 25, Batch 800/836, Loss: 0.0231\n",
            "Epoch 26, Batch 100/836, Loss: 0.0102\n",
            "Epoch 26, Batch 200/836, Loss: 0.0079\n",
            "Epoch 26, Batch 300/836, Loss: 0.0130\n",
            "Epoch 26, Batch 400/836, Loss: 0.0087\n",
            "Epoch 26, Batch 500/836, Loss: 0.0101\n",
            "Epoch 26, Batch 600/836, Loss: 0.0114\n",
            "Epoch 26, Batch 700/836, Loss: 0.0184\n",
            "Epoch 26, Batch 800/836, Loss: 0.0179\n",
            "47m 2s (- 47m 2s) (25 50%) 0.0128\n",
            "Model saved at epoch 25\n",
            "Epoch 27, Batch 100/836, Loss: 0.0062\n",
            "Epoch 27, Batch 200/836, Loss: 0.0097\n",
            "Epoch 27, Batch 300/836, Loss: 0.0072\n",
            "Epoch 27, Batch 400/836, Loss: 0.0131\n",
            "Epoch 27, Batch 500/836, Loss: 0.0100\n",
            "Epoch 27, Batch 600/836, Loss: 0.0114\n",
            "Epoch 27, Batch 700/836, Loss: 0.0114\n",
            "Epoch 27, Batch 800/836, Loss: 0.0106\n",
            "Epoch 28, Batch 100/836, Loss: 0.0086\n",
            "Epoch 28, Batch 200/836, Loss: 0.0065\n",
            "Epoch 28, Batch 300/836, Loss: 0.0079\n",
            "Epoch 28, Batch 400/836, Loss: 0.0136\n",
            "Epoch 28, Batch 500/836, Loss: 0.0101\n",
            "Epoch 28, Batch 600/836, Loss: 0.0118\n",
            "Epoch 28, Batch 700/836, Loss: 0.0140\n",
            "Epoch 28, Batch 800/836, Loss: 0.0131\n",
            "Epoch 29, Batch 100/836, Loss: 0.0087\n",
            "Epoch 29, Batch 200/836, Loss: 0.0082\n",
            "Epoch 29, Batch 300/836, Loss: 0.0190\n",
            "Epoch 29, Batch 400/836, Loss: 0.0119\n",
            "Epoch 29, Batch 500/836, Loss: 0.0065\n",
            "Epoch 29, Batch 600/836, Loss: 0.0089\n",
            "Epoch 29, Batch 700/836, Loss: 0.0063\n",
            "Epoch 29, Batch 800/836, Loss: 0.0140\n",
            "Epoch 30, Batch 100/836, Loss: 0.0103\n",
            "Epoch 30, Batch 200/836, Loss: 0.0120\n",
            "Epoch 30, Batch 300/836, Loss: 0.0069\n",
            "Epoch 30, Batch 400/836, Loss: 0.0071\n",
            "Epoch 30, Batch 500/836, Loss: 0.0105\n",
            "Epoch 30, Batch 600/836, Loss: 0.0088\n",
            "Epoch 30, Batch 700/836, Loss: 0.0108\n",
            "Epoch 30, Batch 800/836, Loss: 0.0092\n",
            "Epoch 31, Batch 100/836, Loss: 0.0081\n",
            "Epoch 31, Batch 200/836, Loss: 0.0085\n",
            "Epoch 31, Batch 300/836, Loss: 0.0107\n",
            "Epoch 31, Batch 400/836, Loss: 0.0092\n",
            "Epoch 31, Batch 500/836, Loss: 0.0042\n",
            "Epoch 31, Batch 600/836, Loss: 0.0101\n",
            "Epoch 31, Batch 700/836, Loss: 0.0100\n",
            "Epoch 31, Batch 800/836, Loss: 0.0081\n",
            "56m 12s (- 37m 28s) (30 60%) 0.0105\n",
            "Model saved at epoch 30\n",
            "Epoch 32, Batch 100/836, Loss: 0.0074\n",
            "Epoch 32, Batch 200/836, Loss: 0.0069\n",
            "Epoch 32, Batch 300/836, Loss: 0.0062\n",
            "Epoch 32, Batch 400/836, Loss: 0.0130\n",
            "Epoch 32, Batch 500/836, Loss: 0.0115\n",
            "Epoch 32, Batch 600/836, Loss: 0.0098\n",
            "Epoch 32, Batch 700/836, Loss: 0.0058\n",
            "Epoch 32, Batch 800/836, Loss: 0.0136\n",
            "Epoch 33, Batch 100/836, Loss: 0.0096\n",
            "Epoch 33, Batch 200/836, Loss: 0.0139\n",
            "Epoch 33, Batch 300/836, Loss: 0.0118\n",
            "Epoch 33, Batch 400/836, Loss: 0.0090\n",
            "Epoch 33, Batch 500/836, Loss: 0.0074\n",
            "Epoch 33, Batch 600/836, Loss: 0.0101\n",
            "Epoch 33, Batch 700/836, Loss: 0.0101\n",
            "Epoch 33, Batch 800/836, Loss: 0.0139\n",
            "Epoch 34, Batch 100/836, Loss: 0.0062\n",
            "Epoch 34, Batch 200/836, Loss: 0.0058\n",
            "Epoch 34, Batch 300/836, Loss: 0.0061\n",
            "Epoch 34, Batch 400/836, Loss: 0.0107\n",
            "Epoch 34, Batch 500/836, Loss: 0.0059\n",
            "Epoch 34, Batch 600/836, Loss: 0.0067\n",
            "Epoch 34, Batch 700/836, Loss: 0.0112\n",
            "Epoch 34, Batch 800/836, Loss: 0.0111\n",
            "Epoch 35, Batch 100/836, Loss: 0.0064\n",
            "Epoch 35, Batch 200/836, Loss: 0.0099\n",
            "Epoch 35, Batch 300/836, Loss: 0.0072\n",
            "Epoch 35, Batch 400/836, Loss: 0.0126\n",
            "Epoch 35, Batch 500/836, Loss: 0.0088\n",
            "Epoch 35, Batch 600/836, Loss: 0.0085\n",
            "Epoch 35, Batch 700/836, Loss: 0.0142\n",
            "Epoch 35, Batch 800/836, Loss: 0.0086\n",
            "Epoch 36, Batch 100/836, Loss: 0.0060\n",
            "Epoch 36, Batch 200/836, Loss: 0.0109\n",
            "Epoch 36, Batch 300/836, Loss: 0.0092\n",
            "Epoch 36, Batch 400/836, Loss: 0.0053\n",
            "Epoch 36, Batch 500/836, Loss: 0.0084\n",
            "Epoch 36, Batch 600/836, Loss: 0.0135\n",
            "Epoch 36, Batch 700/836, Loss: 0.0080\n",
            "Epoch 36, Batch 800/836, Loss: 0.0089\n",
            "66m 10s (- 28m 21s) (35 70%) 0.0092\n",
            "Model saved at epoch 35\n",
            "Epoch 37, Batch 100/836, Loss: 0.0093\n",
            "Epoch 37, Batch 200/836, Loss: 0.0096\n",
            "Epoch 37, Batch 300/836, Loss: 0.0090\n",
            "Epoch 37, Batch 400/836, Loss: 0.0068\n",
            "Epoch 37, Batch 500/836, Loss: 0.0096\n",
            "Epoch 37, Batch 600/836, Loss: 0.0072\n",
            "Epoch 37, Batch 700/836, Loss: 0.0099\n",
            "Epoch 37, Batch 800/836, Loss: 0.0084\n",
            "Epoch 38, Batch 100/836, Loss: 0.0109\n",
            "Epoch 38, Batch 200/836, Loss: 0.0091\n",
            "Epoch 38, Batch 300/836, Loss: 0.0091\n",
            "Epoch 38, Batch 400/836, Loss: 0.0083\n",
            "Epoch 38, Batch 500/836, Loss: 0.0100\n",
            "Epoch 38, Batch 600/836, Loss: 0.0099\n",
            "Epoch 38, Batch 700/836, Loss: 0.0053\n",
            "Epoch 38, Batch 800/836, Loss: 0.0089\n",
            "Epoch 39, Batch 100/836, Loss: 0.0070\n",
            "Epoch 39, Batch 200/836, Loss: 0.0133\n",
            "Epoch 39, Batch 300/836, Loss: 0.0065\n",
            "Epoch 39, Batch 400/836, Loss: 0.0087\n",
            "Epoch 39, Batch 500/836, Loss: 0.0103\n",
            "Epoch 39, Batch 600/836, Loss: 0.0065\n",
            "Epoch 39, Batch 700/836, Loss: 0.0117\n",
            "Epoch 39, Batch 800/836, Loss: 0.0110\n",
            "Epoch 40, Batch 100/836, Loss: 0.0061\n",
            "Epoch 40, Batch 200/836, Loss: 0.0088\n",
            "Epoch 40, Batch 300/836, Loss: 0.0058\n",
            "Epoch 40, Batch 400/836, Loss: 0.0086\n",
            "Epoch 40, Batch 500/836, Loss: 0.0080\n",
            "Epoch 40, Batch 600/836, Loss: 0.0059\n",
            "Epoch 40, Batch 700/836, Loss: 0.0118\n",
            "Epoch 40, Batch 800/836, Loss: 0.0081\n",
            "Epoch 41, Batch 100/836, Loss: 0.0049\n",
            "Epoch 41, Batch 200/836, Loss: 0.0041\n",
            "Epoch 41, Batch 300/836, Loss: 0.0098\n",
            "Epoch 41, Batch 400/836, Loss: 0.0066\n",
            "Epoch 41, Batch 500/836, Loss: 0.0103\n",
            "Epoch 41, Batch 600/836, Loss: 0.0054\n",
            "Epoch 41, Batch 700/836, Loss: 0.0102\n",
            "Epoch 41, Batch 800/836, Loss: 0.0141\n",
            "75m 32s (- 18m 53s) (40 80%) 0.0085\n",
            "Model saved at epoch 40\n",
            "Epoch 42, Batch 100/836, Loss: 0.0053\n",
            "Epoch 42, Batch 200/836, Loss: 0.0081\n",
            "Epoch 42, Batch 300/836, Loss: 0.0061\n",
            "Epoch 42, Batch 400/836, Loss: 0.0053\n",
            "Epoch 42, Batch 500/836, Loss: 0.0058\n",
            "Epoch 42, Batch 600/836, Loss: 0.0077\n",
            "Epoch 42, Batch 700/836, Loss: 0.0064\n",
            "Epoch 42, Batch 800/836, Loss: 0.0045\n",
            "Epoch 43, Batch 100/836, Loss: 0.0074\n",
            "Epoch 43, Batch 200/836, Loss: 0.0069\n",
            "Epoch 43, Batch 300/836, Loss: 0.0035\n",
            "Epoch 43, Batch 400/836, Loss: 0.0087\n",
            "Epoch 43, Batch 500/836, Loss: 0.0066\n",
            "Epoch 43, Batch 600/836, Loss: 0.0058\n",
            "Epoch 43, Batch 700/836, Loss: 0.0093\n",
            "Epoch 43, Batch 800/836, Loss: 0.0106\n",
            "Epoch 44, Batch 100/836, Loss: 0.0044\n",
            "Epoch 44, Batch 200/836, Loss: 0.0074\n",
            "Epoch 44, Batch 300/836, Loss: 0.0104\n",
            "Epoch 44, Batch 400/836, Loss: 0.0120\n",
            "Epoch 44, Batch 500/836, Loss: 0.0072\n",
            "Epoch 44, Batch 600/836, Loss: 0.0047\n",
            "Epoch 44, Batch 700/836, Loss: 0.0088\n",
            "Epoch 44, Batch 800/836, Loss: 0.0090\n",
            "Epoch 45, Batch 100/836, Loss: 0.0143\n",
            "Epoch 45, Batch 200/836, Loss: 0.0041\n",
            "Epoch 45, Batch 300/836, Loss: 0.0088\n",
            "Epoch 45, Batch 400/836, Loss: 0.0102\n",
            "Epoch 45, Batch 500/836, Loss: 0.0098\n",
            "Epoch 45, Batch 600/836, Loss: 0.0064\n",
            "Epoch 45, Batch 700/836, Loss: 0.0109\n",
            "Epoch 45, Batch 800/836, Loss: 0.0129\n",
            "Epoch 46, Batch 100/836, Loss: 0.0024\n",
            "Epoch 46, Batch 200/836, Loss: 0.0075\n",
            "Epoch 46, Batch 300/836, Loss: 0.0143\n",
            "Epoch 46, Batch 400/836, Loss: 0.0092\n",
            "Epoch 46, Batch 500/836, Loss: 0.0088\n",
            "Epoch 46, Batch 600/836, Loss: 0.0076\n",
            "Epoch 46, Batch 700/836, Loss: 0.0090\n",
            "Epoch 46, Batch 800/836, Loss: 0.0117\n",
            "84m 32s (- 9m 23s) (45 90%) 0.0079\n",
            "Model saved at epoch 45\n",
            "Epoch 47, Batch 100/836, Loss: 0.0033\n",
            "Epoch 47, Batch 200/836, Loss: 0.0048\n",
            "Epoch 47, Batch 300/836, Loss: 0.0069\n",
            "Epoch 47, Batch 400/836, Loss: 0.0078\n",
            "Epoch 47, Batch 500/836, Loss: 0.0094\n",
            "Epoch 47, Batch 600/836, Loss: 0.0081\n",
            "Epoch 47, Batch 700/836, Loss: 0.0026\n",
            "Epoch 47, Batch 800/836, Loss: 0.0122\n",
            "Epoch 48, Batch 100/836, Loss: 0.0093\n",
            "Epoch 48, Batch 200/836, Loss: 0.0035\n",
            "Epoch 48, Batch 300/836, Loss: 0.0058\n",
            "Epoch 48, Batch 400/836, Loss: 0.0047\n",
            "Epoch 48, Batch 500/836, Loss: 0.0050\n",
            "Epoch 48, Batch 600/836, Loss: 0.0044\n",
            "Epoch 48, Batch 700/836, Loss: 0.0111\n",
            "Epoch 48, Batch 800/836, Loss: 0.0025\n",
            "Epoch 49, Batch 100/836, Loss: 0.0074\n",
            "Epoch 49, Batch 200/836, Loss: 0.0041\n",
            "Epoch 49, Batch 300/836, Loss: 0.0071\n",
            "Epoch 49, Batch 400/836, Loss: 0.0050\n",
            "Epoch 49, Batch 500/836, Loss: 0.0064\n",
            "Epoch 49, Batch 600/836, Loss: 0.0082\n",
            "Epoch 49, Batch 700/836, Loss: 0.0085\n",
            "Epoch 49, Batch 800/836, Loss: 0.0041\n",
            "Epoch 50, Batch 100/836, Loss: 0.0059\n",
            "Epoch 50, Batch 200/836, Loss: 0.0055\n",
            "Epoch 50, Batch 300/836, Loss: 0.0036\n",
            "Epoch 50, Batch 400/836, Loss: 0.0121\n",
            "Epoch 50, Batch 500/836, Loss: 0.0112\n",
            "Epoch 50, Batch 600/836, Loss: 0.0065\n",
            "Epoch 50, Batch 700/836, Loss: 0.0065\n",
            "Epoch 50, Batch 800/836, Loss: 0.0089\n",
            "Epoch 51, Batch 100/836, Loss: 0.0057\n",
            "Epoch 51, Batch 200/836, Loss: 0.0144\n",
            "Epoch 51, Batch 300/836, Loss: 0.0132\n",
            "Epoch 51, Batch 400/836, Loss: 0.0061\n",
            "Epoch 51, Batch 500/836, Loss: 0.0117\n",
            "Epoch 51, Batch 600/836, Loss: 0.0048\n",
            "Epoch 51, Batch 700/836, Loss: 0.0095\n",
            "Epoch 51, Batch 800/836, Loss: 0.0100\n",
            "94m 2s (- 0m 0s) (50 100%) 0.0077\n",
            "Model saved at epoch 50\n"
          ]
        }
      ],
      "source": [
        "train(train_dataloader, encoder, decoder, n_epochs = 50, print_every=5, plot_every=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqgxfDWKvwOH",
        "outputId": "03751c07-dcc1-47af-95c8-3f56cbd222aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Models saved!\n"
          ]
        }
      ],
      "source": [
        "torch.save(encoder.state_dict(), 'machine_translation\\models\\encoder_final.pth')\n",
        "torch.save(decoder.state_dict(), 'machine_translation\\models\\decoder_final.pth')\n",
        "print(\"Models saved!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "pQC1HymnZ04k"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=60): # Remove features_vocab, target_vocab from arguments\n",
        "    with torch.no_grad():\n",
        "        input_tensor = torch.tensor([features_vocab[token] for token in tokenizer_eng(sentence)], dtype=torch.long, device=device).unsqueeze(0)\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "\n",
        "        decoder_input = torch.tensor([[features_vocab['<bos>']]], device=device)\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        attentions = []\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            decoder_output, decoder_hidden, attn_weights = decoder.forward_step(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            attentions.append(attn_weights)\n",
        "            _, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze(-1).detach()\n",
        "\n",
        "            if topi.item() == target_vocab['<eos>']:\n",
        "                break\n",
        "\n",
        "            decoded_words.append(target_vocab.get_itos()[topi.item()])\n",
        "\n",
        "        return decoded_words, torch.cat(attentions, dim=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Osj-Y77oHqpp"
      },
      "source": [
        "# Inferencing final model on a test instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuMYCnLdahjb",
        "outputId": "558e404c-ba97-4789-bd26-2242875e26aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ورکشاپ مرلن اٹھارہ نظریہ آرہی پیلے جوڑ نرم صوفے فٹ ربی افسردہ وجودی اٹھ قلم کھمبے گیتا مشکلات قرار ڈھونڈا بنوایا مشہور وقفہ ملاتا پردہ باطنی واپس مقامات ہارڈ گلیلیو توقع معجزوں معجزوں دیکھنا مرد پلانٹ تاؤ کلائنٹ زردی آندھی آندھی تلخ کنواری فوجیوں انگور شعبوں چن ڈھالنا برائیوں موزوں وقف الیکٹریشن لہرایا صحت گدلا گدلا لگیں لگیں مٹھائیاں مجموعی\n"
          ]
        }
      ],
      "source": [
        "sentence = \"Can i take your book?\"\n",
        "decoder_output, attn_weights = evaluate(encoder, decoder, sentence)\n",
        "\n",
        "decoder_output_without_pads = [token for token in decoder_output if token != '<pad>']\n",
        "print(' '.join(decoder_output_without_pads))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNJpUVxwHijn"
      },
      "source": [
        "# Load and Inference 5th epochs parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-DpKOspGT7p",
        "outputId": "57ac20f3-01ca-4437-d5b6-71cdee567827"
      },
      "outputs": [],
      "source": [
        "encoder.load_state_dict(torch.load(\"machine_translation\\models\\encoder_final.pth\"))\n",
        "decoder.load_state_dict(torch.load(\"machine_translation\\models\\decoder_final.pth\"))\n",
        "\n",
        "test_sentences = df_clean['english_txt'].sample(5).tolist()  # Take 5 random sentences\n",
        "\n",
        "for sentence in test_sentences:\n",
        "    translated_sentence, _ = evaluate(encoder, decoder, sentence)\n",
        "    translated_sentence_without_pads = [token for token in translated_sentence if token != '<pad>']\n",
        "\n",
        "    print(f\"English: {sentence}\")\n",
        "    print(f\"Translated: {' '.join(translated_sentence_without_pads)}\")\n",
        "    print(\"-\" * 30)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU7NACMbGvK3"
      },
      "source": [
        "# Load and Inference the 10th epoch parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYTh7vn-FAQk",
        "outputId": "20a7840e-5cb4-4e90-e6f8-753bb1b793d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English: he deals in furniture\n",
            "Translated: وہ فرنیچر کا سودا کرتا ہے\n",
            "------------------------------\n",
            "English: none of it was real\n",
            "Translated: قریب تھا\n",
            "------------------------------\n",
            "English: i surrender\n",
            "Translated: میں اضافہ ڈال تا ہوں\n",
            "------------------------------\n",
            "English: phrases for telephone calls\n",
            "Translated: ٹیلیفون کالز کے لئے\n",
            "------------------------------\n",
            "English: the sky is blue\n",
            "Translated: آسمان نیلا ہے\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load the 10th epoch parameters\n",
        "encoder.load_state_dict(torch.load(\"/content/drive/MyDrive/NML_EngtoUrdu_params/encoder_epochs/encoder_epoch_10.pth\"))\n",
        "decoder.load_state_dict(torch.load(\"/content/drive/MyDrive/NML_EngtoUrdu_params/decoder_epochs/decoder_epoch_10.pth\"))\n",
        "\n",
        "test_sentences = df_clean['english_txt'].sample(5).tolist()  # Take 5 random sentences\n",
        "\n",
        "for sentence in test_sentences:\n",
        "    translated_sentence, _ = evaluate(encoder, decoder, sentence)\n",
        "    translated_sentence_without_pads = [token for token in translated_sentence if token != '<pad>']\n",
        "\n",
        "    print(f\"English: {sentence}\")\n",
        "    print(f\"Translated: {' '.join(translated_sentence_without_pads)}\")\n",
        "    print(\"-\" * 30)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQb-ivzOGzJG"
      },
      "source": [
        "# Load and Inference the 20th epoch parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy836V98FdFR",
        "outputId": "f8db339d-5219-4ce7-98c9-c4de61768580"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English: we hope were wrong\n",
            "Translated: امید ہے کہ غلط تھے\n",
            "------------------------------\n",
            "English: zain giggled\n",
            "Translated: زین ہنس نے لگا\n",
            "------------------------------\n",
            "English: these arent words\n",
            "Translated: یہ الفاظ نہیں ہیں\n",
            "------------------------------\n",
            "English: i am undressing\n",
            "Translated: میں پہاڑی ہوں\n",
            "------------------------------\n",
            "English: will you please help me\n",
            "Translated: کیا آپ میری مدد کریں گے\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "encoder.load_state_dict(\n",
        "    torch.load(\"/content/drive/MyDrive/NML_EngtoUrdu_params/encoder_epochs/encoder_epoch_20.pth\"))\n",
        "decoder.load_state_dict(\n",
        "    torch.load(\"/content/drive/MyDrive/NML_EngtoUrdu_params/decoder_epochs/decoder_epoch_20.pth\"))\n",
        "\n",
        "test_sentences = df_clean['english_txt'].sample(5).tolist()  # Take 5 random sentences\n",
        "\n",
        "for sentence in test_sentences:\n",
        "    translated_sentence, _ = evaluate(encoder, decoder, sentence)\n",
        "    translated_sentence_without_pads = [token for token in translated_sentence if token != '<pad>']\n",
        "\n",
        "    print(f\"English: {sentence}\")\n",
        "    print(f\"Translated: {' '.join(translated_sentence_without_pads)}\")\n",
        "    print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxfRYd6pG5gD"
      },
      "source": [
        "# Load and Inference the 30th epoch parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuFGg0KFFuH7",
        "outputId": "889271f4-3531-44c4-8889-e7a2c6dda9ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English: poetic traditions\n",
            "Translated: شاعری برطرف کرتا ہے خریدیں\n",
            "------------------------------\n",
            "English: tom handed a note to mary\n",
            "Translated: ٹام کو ایک نوٹ پکرایا\n",
            "------------------------------\n",
            "English: let me in\n",
            "Translated: مارکیٹ دو\n",
            "------------------------------\n",
            "English: all his teeth are intact\n",
            "Translated: اس کے تمام دانت برقرار تھے\n",
            "------------------------------\n",
            "English: i need somebody\n",
            "Translated: زین ضرورت ہے\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "encoder.load_state_dict(\n",
        "    torch.load(\"/content/drive/MyDrive/NML_EngtoUrdu_params/encoder_epochs/encoder_epoch_30.pth\"))\n",
        "decoder.load_state_dict(\n",
        "    torch.load(\"/content/drive/MyDrive/NML_EngtoUrdu_params/decoder_epochs/decoder_epoch_30.pth\"))\n",
        "\n",
        "test_sentences = df_clean['english_txt'].sample(5).tolist()  # Take 5 random sentences\n",
        "\n",
        "for sentence in test_sentences:\n",
        "    translated_sentence, _ = evaluate(encoder, decoder, sentence)\n",
        "    translated_sentence_without_pads = [token for token in translated_sentence if token != '<pad>']\n",
        "\n",
        "    print(f\"English: {sentence}\")\n",
        "    print(f\"Translated: {' '.join(translated_sentence_without_pads)}\")\n",
        "    print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj2XGLNCG-It"
      },
      "source": [
        "# Load and inference the 40th epoch parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfhuxHiRFyJJ",
        "outputId": "ab657be6-cde4-4987-c097-37ad31555b1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English: i smelled bacon\n",
            "Translated: میں نے بیکن کو سونگھا\n",
            "------------------------------\n",
            "English: i was just angry\n",
            "Translated: میں صرف اندازہ لگایا\n",
            "------------------------------\n",
            "English: zain is a writer\n",
            "Translated: ایک مصنف ہے\n",
            "------------------------------\n",
            "English: say goodbye\n",
            "Translated: خدا حافظ عرصہ پہلے گھبرا خواتین ہوتے ہوں\n",
            "------------------------------\n",
            "English: our train is delayed\n",
            "Translated: ہماری ٹرین تاخیر کا ہے\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "encoder.load_state_dict(\n",
        "    torch.load(\"/content/drive/MyDrive/NML_EngtoUrdu_params/encoder_epochs/encoder_epoch_40.pth\"))\n",
        "decoder.load_state_dict(\n",
        "    torch.load(\"/content/drive/MyDrive/NML_EngtoUrdu_params/decoder_epochs/decoder_epoch_40.pth\"))\n",
        "\n",
        "test_sentences = df_clean['english_txt'].sample(5).tolist()  # Take 5 random sentences\n",
        "\n",
        "for sentence in test_sentences:\n",
        "    translated_sentence, _ = evaluate(encoder, decoder, sentence)\n",
        "    translated_sentence_without_pads = [token for token in translated_sentence if token != '<pad>']\n",
        "\n",
        "    print(f\"English: {sentence}\")\n",
        "    print(f\"Translated: {' '.join(translated_sentence_without_pads)}\")\n",
        "    print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRkLM6b5HH71"
      },
      "source": [
        "# Load and inference the 50th epoch parameters\n",
        "\n",
        "# (Final model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the model state dict with map_location to handle CPU-only environment\n",
        "encoder_path = r\"G:\\CampusX\\Onsite Projects\\Pytorch-NMT\\Neural_Machine_Translation\\Eng_to_Urdu_Translation\\models copy\\encoder_final.pth\"\n",
        "decoder_path = r\"G:\\CampusX\\Onsite Projects\\Pytorch-NMT\\Neural_Machine_Translation\\Eng_to_Urdu_Translation\\models copy\\decoder_final.pth\"\n",
        "encoder_state_dict = torch.load(encoder_path, map_location=torch.device('cpu'))\n",
        "decoder_state_dict = torch.load(decoder_path, map_location=torch.device('cpu'))\n",
        "\n",
        "# Assuming you have already defined your encoder and decoder models\n",
        "encoder.load_state_dict(encoder_state_dict)\n",
        "decoder.load_state_dict(decoder_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2rfxk6zGNhn",
        "outputId": "003791c0-551e-4356-845e-01dd1bec387a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English: get rid of her\n",
            "Translated: غسل خانہ کہاں ہیں\n",
            "------------------------------\n",
            "English: zain walked\n",
            "Translated: چلا\n",
            "------------------------------\n",
            "English: thanks for saving me\n",
            "Translated: مجھے مارا\n",
            "------------------------------\n",
            "English: where is the embassy\n",
            "Translated: یا گاڑی دشمن ہے\n",
            "------------------------------\n",
            "English: you ruined it\n",
            "Translated: اسے دیکھا\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "test_sentences = df_clean['english_txt'].sample(5).tolist()  # Take 5 random sentences\n",
        "\n",
        "for sentence in test_sentences:\n",
        "    translated_sentence, _ = evaluate(encoder, decoder, sentence)\n",
        "    translated_sentence_without_pads = [token for token in translated_sentence if token != '<pad>']\n",
        "\n",
        "    print(f\"English: {sentence}\")\n",
        "    print(f\"Translated: {' '.join(translated_sentence_without_pads)}\")\n",
        "    print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTlWt2G7NcT7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6Pi4ZkpNcQi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_DQJ1zINcOH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
